import logging
import asyncio
import re
from typing import List, Dict, Any, Tuple, Iterable, Optional
from src.db.connection import DBConnection
from src.config.settings import settings
from src.utils.cleaning import normalize_numeric_string
from src.etl.cdc_processor import compute_row_hash, CDCProcessor

log = logging.getLogger('loader')

class DataLoader:
    def __init__(self):
        self.schema_prefix = 'staging.' if settings.use_staging_schema else ''
        # –°—Ç—Ä–æ–≥–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è: –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –±—É–∫–≤—ã, —Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã, —Ü–∏—Ñ—Ä—ã –∏ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–µ.
        self._single_ident_pattern = re.compile(r'^[a-zA-Z][a-zA-Z0-9_]*$')

    def _validate_identifier(self, ident: str) -> str:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä (—Ç–∞–±–ª–∏—Ü–∞/–∫–æ–ª–æ–Ω–∫–∞) –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –∏–Ω—ä–µ–∫—Ü–∏–π."""
        if not ident:
            raise ValueError("–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
        
        # –ï—Å–ª–∏ —ç—Ç–æ –ø–æ–ª–Ω–æ–µ –∏–º—è —Ç–∞–±–ª–∏—Ü—ã —Å–æ —Å—Ö–µ–º–æ–π (schema.table)
        if '.' in ident:
            parts = ident.split('.')
            if len(parts) != 2:
                raise ValueError(f"–ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–π —Ñ–æ—Ä–º–∞—Ç –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ (–æ–∂–∏–¥–∞–ª–æ—Å—å schema.table): {ident}")
            for part in parts:
                if not self._single_ident_pattern.match(part):
                    raise ValueError(f"–ù–µ–¥–æ–ø—É—Å—Ç–∏–º–∞—è —á–∞—Å—Ç—å –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞: {part}")
        else:
            # –û–¥–∏–Ω–æ—á–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä (–∫–æ–ª–æ–Ω–∫–∞ –∏–ª–∏ —Ç–∞–±–ª–∏—Ü–∞ –±–µ–∑ —Å—Ö–µ–º—ã)
            if not self._single_ident_pattern.match(ident):
                raise ValueError(f"–ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä: {ident}")
        
        return ident

    def _format_table_name(self, table: str) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∏–º—è —Ç–∞–±–ª–∏—Ü—ã, —É—á–∏—Ç—ã–≤–∞—è —Å—Ö–µ–º—É (stg.table -> "stg"."table")."""
        table = self._validate_identifier(table)
        if '.' in table:
            schema, tbl = table.split('.', 1)
            return f'"{schema}"."{tbl}"'
        
        # –ï—Å–ª–∏ —Å—Ö–µ–º—ã –Ω–µ—Ç –≤ –∏–º–µ–Ω–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ—Ñ–∏–∫—Å –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        return f'{self.schema_prefix}"{table}"'

    def _prepare_row(self, r: List[Any], col_names: List[str], row_num: int) -> Tuple[List[str], str]:
        """–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ç—Ä–æ–∫–∏: –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ, –æ—á–∏—Å—Ç–∫–∞, —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ."""
        # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –∏ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ —Å—Ç—Ä–æ–∫–µ
        full_row = list(r) + [None] * (len(col_names) - len(r))
        full_row = full_row[:len(col_names)]
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö (–≤—Å—ë –≤ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è)
        full_row_str = [normalize_numeric_string(val) for val in full_row]
        row_hash = compute_row_hash(full_row_str)
        
        return full_row_str, row_hash

    async def load_full_refresh(self, table: str, col_names: List[str], rows: Iterable[List[Any]], row_count: Optional[int] = None) -> Dict[str, int]:
        """–ü–æ–ª–Ω–∞—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ —Ç–∞–±–ª–∏—Ü—ã: TRUNCATE + INSERT."""
        if '.' not in table:
             table = self._validate_identifier(table)
        
        target_table_sql = self._format_table_name(table)
        validated_cols = [self._validate_identifier(c) for c in col_names]
        
        # Determine count for logging (handle Generator)
        count_str = f"{row_count} —Å—Ç—Ä–æ–∫" if row_count is not None else "? —Å—Ç—Ä–æ–∫"
        if row_count is None and isinstance(rows, list):
             count_str = f"{len(rows)} —Å—Ç—Ä–æ–∫"

        log.info(f"–ù–∞—á–∞–ª–æ –ø–æ–ª–Ω–æ–π –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏ {target_table_sql} ({count_str})")
        stats = {'inserted': 0, 'errors': 0}
        
        async with await DBConnection.get_connection() as conn:
            async with conn.transaction():
                await conn.execute(f'TRUNCATE TABLE {target_table_sql}')
                
                prepared_records = []
                target_cols = validated_cols + ["_row_index", "__row_hash"]
                
                for idx, r in enumerate(rows):
                    row_num = idx + 2
                    try:
                        full_row_str, row_hash = self._prepare_row(r, col_names, row_num)
                        prepared_records.append(tuple(full_row_str + [row_num, row_hash]))
                    except Exception as e:
                        log.warning(f"–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ —Å—Ç—Ä–æ–∫–∏ {row_num}: {e}")
                        stats['errors'] += 1
                
                if prepared_records:
                    if '.' in table:
                        target_schema = table.split('.', 1)[0]
                        target_table_only = table.split('.', 1)[1]
                    else:
                        target_schema = self.schema_prefix.replace('.', '') if self.schema_prefix else None
                        target_table_only = table
                        
                    await conn.copy_records_to_table(
                        target_table_only,
                        schema_name=target_schema,
                        records=prepared_records,
                        columns=target_cols
                    )
                    stats['inserted'] = len(prepared_records)
                    
        log.info(f"–ü–æ–ª–Ω–∞—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ {table} –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {stats}")
        return stats

    async def load_cdc(self, table: str, col_names: List[str], rows: Iterable[List[Any]], pk_field: str = '__row_hash', row_count: Optional[int] = None) -> Dict[str, int]:
        """–ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º CDC."""
        if '.' not in table:
             table = self._validate_identifier(table)
        pk_field = self._validate_identifier(pk_field)
        target_table_sql = self._format_table_name(table)
        
        count_str = f"{row_count} —Å—Ç—Ä–æ–∫" if row_count is not None else "? —Å—Ç—Ä–æ–∫"
        if row_count is None and isinstance(rows, list):
             count_str = f"{len(rows)} —Å—Ç—Ä–æ–∫"

        log.info(f"CDC –∑–∞–≥—Ä—É–∑–∫–∞ –≤ {target_table_sql} ({count_str} –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞) [PK: {pk_field}]")
        
        existing_hashes = await self._fetch_existing_hashes(table, pk_field)
        processor = CDCProcessor(existing_hashes)
        
        for idx, r in enumerate(rows):
            row_num = idx + 2
            try:
                full_row_str, row_hash = self._prepare_row(r, col_names, row_num)
                
                # PK identification
                if pk_field == '__row_hash':
                    pk_val = row_hash
                elif pk_field in col_names:
                    pk_idx = col_names.index(pk_field)
                    pk_val = full_row_str[pk_idx]
                else:
                    pk_val = None

                if not pk_val:
                     continue

                row_data = {col: val for col, val in zip(col_names, full_row_str)}
                row_data['_row_index'] = row_num
                
                processor.process_row(pk_val, row_hash, row_data)
            except Exception as e:
                log.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–æ–∫–∏ {row_num} –¥–ª—è CDC: {e}")

        processor.finalize()
        cdc_stats = processor.get_stats()
        await self._apply_cdc_changes(table, processor, col_names, pk_field)
        return cdc_stats

    async def calculate_changes(self, table: str, col_names: List[str], rows: Iterable[List[Any]], pk_field: str = '__row_hash', row_count: Optional[int] = None) -> Dict[str, int]:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑–º–µ–Ω–µ–Ω–∏–π –±–µ–∑ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è (–¥–ª—è dry-run)."""
        if '.' not in table:
             table = self._validate_identifier(table)
        target_table_sql = self._format_table_name(table)
        pk_field = self._validate_identifier(pk_field)
        
        count_str = f"{row_count} —Å—Ç—Ä–æ–∫" if row_count is not None else "? —Å—Ç—Ä–æ–∫"
        if row_count is None and isinstance(rows, list):
             count_str = f"{len(rows)} —Å—Ç—Ä–æ–∫"

        log.info(f"üîç [DRY-RUN] –†–∞—Å—á–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π –¥–ª—è {target_table_sql} ({count_str}) [PK: {pk_field}]")
        
        existing_hashes = await self._fetch_existing_hashes(table, pk_field)
        processor = CDCProcessor(existing_hashes)
        
        for idx, r in enumerate(rows):
            row_num = idx + 2
            try:
                full_row_str, row_hash = self._prepare_row(r, col_names, row_num)
                
                if pk_field == '__row_hash':
                    pk_val = row_hash
                elif pk_field in col_names:
                    pk_idx = col_names.index(pk_field)
                    pk_val = full_row_str[pk_idx]
                else:
                    pk_val = None
                
                if not pk_val:
                    continue

                row_data = {col: val for col, val in zip(col_names, full_row_str)}
                processor.process_row(pk_val, row_hash, row_data)
            except Exception as e:
                log.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–æ–∫–∏ {row_num} (dry-run): {e}")

        processor.finalize()
        return processor.get_stats()

    async def _fetch_existing_hashes(self, table: str, pk_field: str) -> Dict[str, str]:
        # table –∏ pk_field —É–∂–µ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω—ã –≤—ã—à–µ
        # table –∏ pk_field —É–∂–µ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω—ã –≤—ã—à–µ (–≤ –≤—ã–∑—ã–≤–∞—é—â–µ–º –º–µ—Ç–æ–¥–µ) –∏–ª–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∑–¥–µ—Å—å
        target_table_sql = self._format_table_name(table)
        try:
            query = f'SELECT "{pk_field}" as pk, __row_hash FROM {target_table_sql} WHERE "{pk_field}" IS NOT NULL'
            rows = await DBConnection.fetch(query)
            return {str(row['pk']): row['__row_hash'] for row in rows if row['__row_hash']}
        except Exception as e:
            log.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ö–µ—à–∏ –¥–ª—è {table} (–∫–æ–ª–æ–Ω–∫–∞ {pk_field} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç?): {e}")
            return {}

    async def _apply_cdc_changes(self, table: str, processor: CDCProcessor, col_names: List[str], pk_field: str):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç INSERT/UPDATE/DELETE –∑–∞–ø—Ä–æ—Å—ã."""
        if '.' not in table:
             table = self._validate_identifier(table)
        target_table_sql = self._format_table_name(table)
        validated_cols = [self._validate_identifier(c) for c in col_names]
        pk_field = self._validate_identifier(pk_field)

        async with await DBConnection.get_connection() as conn:
            # INSERTs
            if processor.to_insert:
                cols_str = ', '.join([f'"{c}"' for c in validated_cols] + ['"_row_index"', '"__row_hash"'])
                placeholders = ', '.join([f'${i+1}' for i in range(len(validated_cols) + 2)])
                insert_query = f'INSERT INTO {target_table_sql} ({cols_str}) VALUES ({placeholders})'
                
                for item in processor.to_insert:
                    data = item['data']
                    values = [data.get(c) for c in col_names] + [data.get('_row_index'), item['hash']]
                    await conn.execute(insert_query, *values)

            # UPDATEs
            if processor.to_update:
                for item in processor.to_update:
                    data = item['data']
                    pk_val = item['pk']
                    
                    set_parts = []
                    vals = []
                    idx = 1
                    for c in col_names:
                        if c == pk_field: continue
                        set_parts.append(f'"{c}" = ${idx}')
                        vals.append(data.get(c))
                        idx += 1
                    
                    set_parts.append(f'"__row_hash" = ${idx}')
                    vals.append(item['hash'])
                    idx += 1
                    vals.append(pk_val) # PK for WHERE
                    
                    query = f'UPDATE {target_table_sql} SET {", ".join(set_parts)} WHERE "{pk_field}" = ${idx}'
                    await conn.execute(query, *vals)

            # DELETEs
            if processor.to_delete:
                del_query = f'DELETE FROM {target_table_sql} WHERE "{pk_field}" = $1'
                for pk_val in processor.to_delete:
                    await conn.execute(del_query, pk_val)
                log.info(f"–£–¥–∞–ª–µ–Ω–æ {len(processor.to_delete)} —Å—Ç—Ä–æ–∫ –∏–∑ {table}")
