import logging
import time
import uuid
from typing import Optional, List, Dict, Any
from src.config.settings import settings
from src.etl.extractor import GSheetsExtractor
from src.etl.loader import DataLoader
from src.etl.transformer import Transformer
from src.etl.exporter import DataMartExporter
from src.etl.validator import ContractValidator, ValidationResult
from src.db.connection import DBConnection

log = logging.getLogger('pipeline')


class ELTPipeline:
    """–û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä ELT –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –º–µ—Ç—Ä–∏–∫."""
    
    def __init__(self):
        self.extractor = GSheetsExtractor()
        self.loader = DataLoader()
        self.transformer = Transformer()
        self.exporter = DataMartExporter()
        self.validator = ContractValidator()
        self.run_id = uuid.uuid4()
        self._run_stats = {
            'tables_processed': 0,
            'total_rows_synced': 0,
            'validation_errors': 0
        }
        self._table_run_details = []

    async def run(self, 
                  skip_load: bool = False, 
                  skip_transform: bool = False, 
                  full_refresh: bool = False,
                  dry_run: bool = False,
                  scope: str = 'all',
                  run_exports: bool = True):
        """–ó–∞–ø—É—Å–∫ ETL –ø–∞–π–ø–ª–∞–π–Ω–∞.
        
        Args:
            skip_load: –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Ñ–∞–∑—É –∑–∞–≥—Ä—É–∑–∫–∏
            skip_transform: –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Ñ–∞–∑—É —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏  
            full_refresh: –ü–æ–ª–Ω–∞—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ (TRUNCATE + INSERT)
            dry_run: –ü–æ–∫–∞–∑–∞—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è –±–µ–∑ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è
            scope: –û–±–ª–∞—Å—Ç—å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ (all, current, historical)
        """
        self.dry_run = dry_run
        start_time = time.time()
        mode = '–ø–æ–ª–Ω–∞—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞' if full_refresh else '–∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ (CDC)'
        error_message = None
        
        log.info(f"=== –ó–∞–ø—É—Å–∫ ELT –ü–∞–π–ø–ª–∞–π–Ω–∞ (ID: {self.run_id}) ===")
        log.info(f"–†–µ–∂–∏–º: {mode}, Scope: {scope}")
        
        # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –Ω–∞—á–∞–ª–æ run
        await self._start_run('full_refresh' if full_refresh else 'cdc')
        
        try:
            if not skip_load:
                await self._run_load_phase(full_refresh, scope)
            else:
                log.info("–ü—Ä–æ–ø—É—Å–∫ —Ñ–∞–∑—ã –∑–∞–≥—Ä—É–∑–∫–∏ (skip_load=True)")

            if not skip_transform:
                await self._run_transform_phase()
            else:
                log.info("–ü—Ä–æ–ø—É—Å–∫ —Ñ–∞–∑—ã —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ (skip_transform=True)")
            
            # 4. –≠–∫—Å–ø–æ—Ä—Ç –≤–∏—Ç—Ä–∏–Ω
            if run_exports and not dry_run:
                await self._run_export_phase()
                
            status = 'success'
        except Exception as e:
            status = 'failed'
            error_message = str(e)
            log.critical(f"–°–±–æ–π –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞: {e}", exc_info=True)
            raise
        finally:
            duration = time.time() - start_time
            await self._finish_run(status, duration, error_message)
            self._print_summary_table(status, duration)
            log.info(f"=== –ü–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {duration:.2f} —Å–µ–∫ (—Å—Ç–∞—Ç—É—Å: {status}) ===")

    async def _start_run(self, mode: str):
        """–†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç –Ω–∞—á–∞–ª–æ run –≤ elt_runs."""
        query = """
            INSERT INTO elt_runs (run_id, mode, status)
            VALUES ($1, $2, 'running')
        """
        try:
            await DBConnection.execute(query, str(self.run_id), mode)
        except Exception as e:
            log.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–∞—á–∞–ª–æ –∑–∞–ø—É—Å–∫–∞: {e}")

    async def _finish_run(self, status: str, duration: float, error_message: Optional[str] = None):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç elt_runs —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ run."""
        query = """
            UPDATE elt_runs SET
                finished_at = NOW(),
                status = $2,
                duration_seconds = $3,
                tables_processed = $4,
                total_rows_synced = $5,
                validation_errors = $6,
                error_message = $7
            WHERE run_id = $1
        """
        try:
            await DBConnection.execute(
                query,
                str(self.run_id),
                status,
                round(duration, 2),
                self._run_stats['tables_processed'],
                self._run_stats['total_rows_synced'],
                self._run_stats['validation_errors'],
                error_message
            )
        except Exception as e:
            log.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è: {e}")

    async def _log_table_stats(self, table_name: str, stats: Dict[str, int], 
                                validation_errors: int, duration_ms: int):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ç–∞–±–ª–∏—Ü–µ –≤ elt_table_stats."""
        query = """
            INSERT INTO elt_table_stats (
                run_id, table_name, rows_extracted, rows_inserted, 
                rows_updated, rows_deleted, rows_unchanged, validation_errors, duration_ms
            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
        """
        try:
            await DBConnection.execute(
                query,
                str(self.run_id),
                table_name,
                stats.get('extracted', 0),
                stats.get('inserted', 0),
                stats.get('updated', 0),
                stats.get('deleted', 0),
                stats.get('unchanged', 0),
                validation_errors,
                duration_ms
            )
        except Exception as e:
            log.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–∞–±–ª–∏—Ü—ã {table_name}: {e}")

    async def _run_load_phase(self, full_refresh: bool, scope: str = 'all'):
        dry_run_mode = getattr(self, 'dry_run', False)
        mode_label = ' [DRY-RUN]' if dry_run_mode else ''
        log.info(f"–ù–∞—á–∞–ª–æ —Ñ–∞–∑—ã –∑–∞–≥—Ä—É–∑–∫–∏{mode_label} (–¢–∏–ø: {'Full Refresh' if full_refresh else 'CDC'})")
        
        config = settings.sources
        if not config:
            log.warning("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è sources.yml –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
            return

        for spreadsheet_id, sdata in config.get('spreadsheets', {}).items():
            for sheet_cfg in sdata.get('sheets', []):
                target_table = sheet_cfg['target_table']
                
                # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ scope
                is_cur = target_table.endswith('_cur')
                is_hst = target_table.endswith('_hst')
                is_ref = target_table in ('rates', 'price_reference')
                
                if scope == 'current' and not is_cur:
                    continue
                if scope == 'historical' and not (is_hst or is_ref):
                    continue
                
                gid = sheet_cfg.get('gid', 0)
                range_name = sheet_cfg.get('range', 'A:Z')
                mode = sheet_cfg.get('mode', 'upsert')
                
                contract_name = target_table.replace('_cur', '').replace('_hst', '')
                if contract_name == 'trainings':
                    contract_name = 'schedule'
                
                is_full_refresh = full_refresh or (mode == 'replace')
                table_start = time.time()
                validation_errors = 0
                
                try:
                    mapping = sheet_cfg.get('column_mapping')
                    
                    # 1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ
                    col_names, rows = await self.extractor.extract_sheet_data(
                        spreadsheet_id, str(gid), range_name, target_table, 
                        mapping=mapping
                    )
                    
                    if not rows:
                        log.info(f"–¢–∞–±–ª–∏—Ü–∞ {target_table}: –¥–∞–Ω–Ω—ã—Ö –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ, –ø—Ä–æ–ø—É—Å–∫.")
                        continue
                        
                    # 1.5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö (Audit Trace)
                    await self._dump_raw_data(spreadsheet_id, target_table, col_names, rows)

                    # 2. –í–∞–ª–∏–¥–∞—Ü–∏—è
                    log.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞ '{contract_name}' –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã {target_table}...")
                    dict_rows = [dict(zip(col_names, row)) for row in rows]
                    val_result = self.validator.validate_dataset(dict_rows, contract_name)
                    
                    if not val_result.is_valid:
                        validation_errors = len(val_result.errors)
                        log.warning(f"‚ö† {target_table}: –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ {validation_errors} –æ—à–∏–±–æ–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏")
                        
                        if not dry_run_mode:
                            await self._log_validation_errors(target_table, val_result)

                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ä–æ–≥–æ–≤ –æ—à–∏–±–æ–∫
                        # 1. –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –æ—à–∏–±–æ–∫ –≤—Å–µ–≥–æ
                        if validation_errors > 20:
                             raise ValueError(f"–ö–†–ò–¢–ò–ß–ù–û: {validation_errors} –æ—à–∏–±–æ–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤ {target_table} (> 20). –ü—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ.")
                        
                        # 2. –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –æ—à–∏–±–æ–∫ –≤ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ (–±–∏—Ç–∞—è —Å—Ç—Ä–æ–∫–∞)
                        errors_by_row = {}
                        for err in val_result.errors:
                            errors_by_row[err.row_index] = errors_by_row.get(err.row_index, 0) + 1
                        
                        if any(count > 5 for count in errors_by_row.values()):
                             raise ValueError(f"–ö–†–ò–¢–ò–ß–ù–û: –ù–∞–π–¥–µ–Ω—ã —Å—Ç—Ä–æ–∫–∏ —Å >5 –æ—à–∏–±–∫–∞–º–∏ –≤ {target_table}. –í–æ–∑–º–æ–∂–Ω–æ, –±–∏—Ç—ã–π —Ñ–æ—Ä–º–∞—Ç —Å—Ç—Ä–æ–∫.")

                    else:
                        log.info(f"‚úì {target_table}: –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")

                    pk_field = sheet_cfg.get('pk', '__row_hash')

                    # 3. –ó–∞–≥—Ä—É–∑–∫–∞
                    if dry_run_mode:
                        load_stats = await self.loader.calculate_changes(target_table, col_names, rows, pk_field)
                        log.info(f"üîç [DRY-RUN] {target_table}: "
                                f"–±—ã–ª–æ –±—ã: –¥–æ–∑–∞–ø–∏—Å—å={load_stats.get('insert', 0)}, "
                                f"–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ={load_stats.get('update', 0)}, "
                                f"—É–¥–∞–ª–µ–Ω–∏–µ={load_stats.get('delete', 0)}, "
                                f"–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π={load_stats.get('unchanged', 0)}")
                    elif is_full_refresh:
                        load_stats = await self.loader.load_full_refresh(target_table, col_names, rows)
                    else:
                        load_stats = await self.loader.load_cdc(target_table, col_names, rows, pk_field)
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                    load_stats['extracted'] = len(rows)
                    duration_ms = int((time.time() - table_start) * 1000)
                    
                    self._run_stats['tables_processed'] += 1
                    self._run_stats['total_rows_synced'] += load_stats.get('inserted', 0) + load_stats.get('updated', 0)
                    self._run_stats['validation_errors'] += validation_errors
                    
                    self._table_run_details.append({
                        'table': target_table,
                        'extracted': load_stats.get('extracted', 0),
                        'inserted': load_stats.get('inserted', 0),
                        'updated': load_stats.get('updated', 0),
                        'deleted': load_stats.get('deleted', 0),
                        'errors': validation_errors,
                        'duration_s': round(duration_ms / 1000, 2)
                    })
                    
                    if not dry_run_mode:
                        await self._log_table_stats(target_table, load_stats, validation_errors, duration_ms)
                        
                except Exception as e:
                    log.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–∞–±–ª–∏—Ü—ã {target_table}: {e}")

    async def _log_validation_errors(self, table_name: str, result: ValidationResult):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –æ—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤ –ë–î."""
        query = """
            INSERT INTO validation_logs (
                run_id, table_name, row_index, column_name, 
                invalid_value, error_type, message
            ) VALUES ($1, $2, $3, $4, $5, $6, $7)
        """
        params = [
            (
                str(self.run_id),
                table_name,
                err.row_index,
                err.column,
                str(err.value)[:255] if err.value is not None else None,
                err.error_type,
                err.message
            )
            for err in result.errors
        ]
        
        try:
            async with await DBConnection.get_connection() as conn:
                await conn.executemany(query, params)
            log.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(params)} –æ—à–∏–±–æ–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤ –ë–î.")
        except Exception as e:
            log.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ª–æ–≥–∏ –æ—à–∏–±–æ–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")

    async def _dump_raw_data(self, spreadsheet_id: str, sheet_name: str, col_names: list, rows: list):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ —Å—Ö–µ–º—É raw."""
        import json
        query = """
            INSERT INTO raw.sheets_dump (spreadsheet_id, sheet_name, data)
            VALUES ($1, $2, $3)
        """
        try:
            # –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º –≤ —Å–ø–∏—Å–æ–∫ –¥–∏–∫—Ç–æ–≤ –¥–ª—è JSONB
            data_to_dump = [dict(zip(col_names, row)) for row in rows[:1000]] # –û–≥—Ä–∞–Ω–∏—á–∏–º –¥–ª—è –ª–æ–≥–∞ –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ? 
            # –ù–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –ª—É—á—à–µ –≤—Å—ë, –Ω–æ jsonb –∏–º–µ–µ—Ç –ø—Ä–µ–¥–µ–ª—ã. Sheets —Ä–µ–¥–∫–æ > 100mb.
            # –î–ª—è –∞—É–¥–∏—Ç–∞ –æ–±—ã—á–Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏ –ø–µ—Ä–≤—ã—Ö —Å—Ç—Ä–æ–∫, –Ω–æ –≤ –∏–¥–µ–∞–ª–µ –≤—Å—ë.
            full_data = json.dumps([dict(zip(col_names, row)) for row in rows], ensure_ascii=False)
            
            await DBConnection.execute(query, spreadsheet_id, sheet_name, full_data)
            log.debug(f"–°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {sheet_name} —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ raw.sheets_dump")
        except Exception as e:
            log.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {sheet_name}: {e}")

    async def _run_transform_phase(self):
        log.info("–ù–∞—á–∞–ª–æ —Ñ–∞–∑—ã —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏...")
        await self.transformer.run()

    async def _run_export_phase(self):
        """–≠–∫—Å–ø–æ—Ä—Ç –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –≤–∏—Ç—Ä–∏–Ω."""
        log.info("–ù–∞—á–∞–ª–æ —Ñ–∞–∑—ã —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤–∏—Ç—Ä–∏–Ω...")
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥ –≤–∏—Ç—Ä–∏–Ω –∏–∑ settings (–¥–æ–±–∞–≤–∏–º –µ–≥–æ –≤ sources.yml)
        datamarts = settings.sources.get('datamarts', [])
        for dm in datamarts:
            try:
                await self.exporter.export_view_to_sheet(
                    view_name=dm['view'],
                    spreadsheet_id=dm['spreadsheet_id'],
                    gid=dm['gid']
                )
            except Exception as e:
                log.error(f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤–∏—Ç—Ä–∏–Ω—ã {dm.get('view')}: {e}")

    def _print_summary_table(self, status: str, duration: float):
        """–í—ã–≤–æ–¥–∏—Ç –∏—Ç–æ–≥–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É –≤ –∫–æ–Ω—Å–æ–ª—å."""
        if not self._table_run_details:
            return
            
        print("\n" + "="*80)
        print(f"–ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ ELT (Run ID: {str(self.run_id)[:8]}...)")
        print(f"–°—Ç–∞—Ç—É—Å: {status.upper()} | –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration:.2f} —Å–µ–∫")
        print("-" * 80)
        # –ë–æ–ª–µ–µ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        print(f"{'–¢–∞–±–ª–∏—Ü–∞':<20} | {'–í—Å–µ–≥–æ':<5} | {'INS':<4} | {'UPD':<4} | {'DEL':<4} | {'ERR':<4} | {'–í—Ä–µ–º—è':<6}")
        print("-" * 80)
        
        for d in self._table_run_details:
            print(f"{d['table']:<20} | {d['extracted']:<5} | {d['inserted']:<4} | {d['updated']:<4} | {d['deleted']:<4} | {d['errors']:<4} | {d['duration_s']:>6.2f}s")
        
        print("-" * 80)
        print(f"{'–ò–¢–û–ì–û':<20} | {sum(d['extracted'] for d in self._table_run_details):<5} | "
              f"{sum(d['inserted'] for d in self._table_run_details):<4} | "
              f"{sum(d['updated'] for d in self._table_run_details):<4} | "
              f"{sum(d['deleted'] for d in self._table_run_details):<4} | "
              f"{self._run_stats['validation_errors']:<4} | {duration:>6.2f}s")
        print("="*80 + "\n")
